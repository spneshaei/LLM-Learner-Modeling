{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file prepares the JSONL files to be submitted to OpenAI's fine-tuning API. All experiments are done with the `babbage-002` GPT-3 model on February 2023, with default fine-tuning parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration variables\n",
    "\n",
    "dataset_name = \"statics\" # statics, assistments09, assistments17\n",
    "approach = \"minimal\" # minimal, extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and helper functions\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "class NpEncoder(json.JSONEncoder): # to fix the \"Object of type 'int64' is not JSON serializable\" error. Source: https://stackoverflow.com/a/57915246\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "    \n",
    "# From https://galea.medium.com/how-to-love-jsonl-using-json-line-format-in-your-workflow-b6884f65175b\n",
    "\n",
    "from json import JSONEncoder\n",
    "\n",
    "class MyEncoder(JSONEncoder):\n",
    "        def default(self, o):\n",
    "            return o.__dict__ \n",
    "\n",
    "import json\n",
    "\n",
    "def dump_jsonl(data, output_path, append=False):\n",
    "    \"\"\"\n",
    "    Write list of objects to a JSON lines file.\n",
    "    \"\"\"\n",
    "    mode = 'a+' if append else 'w'\n",
    "    with open(output_path, mode, encoding='utf-8') as f:\n",
    "        for line in data:\n",
    "            json_record = json.dumps(line, ensure_ascii=False, cls=MyEncoder)\n",
    "            f.write(json_record + '\\n')\n",
    "    print('Wrote {} records to {}'.format(len(data), output_path))\n",
    "\n",
    "def load_jsonl(input_path) -> list:\n",
    "    \"\"\"\n",
    "    Read list of objects from a JSON lines file.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.rstrip('\\n|\\r')))\n",
    "    print('Loaded {} records from {}'.format(len(data), input_path))\n",
    "    return data\n",
    "\n",
    "class JSONLDataObject:\n",
    "    prompt = \"\"\n",
    "    completion = \"\"\n",
    "\n",
    "    def __init__(self, prompt, completion):\n",
    "        self.prompt = prompt\n",
    "        self.completion = completion\n",
    "\n",
    "    def __repr__(self):\n",
    "        return repr((self.prompt, self.completion))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the input files\n",
    "full_train_df = pd.read_csv(f'../initial_data/{dataset_name}/preprocessed_data_train.csv', sep='\\t')\n",
    "full_test_df = pd.read_csv(f'../initial_data/{dataset_name}/preprocessed_data_test.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find statistics about the dataset\n",
    "\n",
    "print(\"In train set:\")\n",
    "print(\"Number of entries:\", len(full_train_df))\n",
    "print(\"Unique problem IDs:\", len(full_train_df['item_id'].unique()))\n",
    "print(\"Unique user IDs:\", len(full_train_df['user_id'].unique()))\n",
    "print(\"Set of possible answers for each question:\", full_train_df['correct'].unique())\n",
    "print(\"Number of wrong answers:\", len(full_train_df[full_train_df['correct'] == 0]))\n",
    "print(\"Number of correct answers:\", len(full_train_df[full_train_df['correct'] == 1]))\n",
    "print(\"\")\n",
    "\n",
    "print(\"In test set:\")\n",
    "print(\"Number of entries:\", len(full_test_df))\n",
    "print(\"Unique problem IDs:\", len(full_test_df['item_id'].unique()))\n",
    "print(\"Unique user IDs:\", len(full_test_df['user_id'].unique()))\n",
    "print(\"Set of possible answers for each question:\", full_test_df['correct'].unique())\n",
    "print(\"Number of wrong answers:\", len(full_test_df[full_test_df['correct'] == 0]))\n",
    "print(\"Number of correct answers:\", len(full_test_df[full_test_df['correct'] == 1]))\n",
    "print(\"===\")\n",
    "\n",
    "# concat the train and test sets\n",
    "full_df = pd.concat([full_train_df, full_test_df])\n",
    "\n",
    "print(\"In the whole dataset:\")\n",
    "print(\"Number of entries:\", len(full_df))\n",
    "print(\"Unique problem IDs:\", len(full_df['item_id'].unique()))\n",
    "print(\"Unique user IDs:\", len(full_df['user_id'].unique()))\n",
    "print(\"Set of possible answers for each question:\", full_df['correct'].unique())\n",
    "print(\"Number of wrong answers:\", len(full_df[full_df['correct'] == 0]))\n",
    "print(\"Number of correct answers:\", len(full_df[full_df['correct'] == 1]))\n",
    "\n",
    "# Find if there are any user IDs common between the train and test sets\n",
    "\n",
    "print(\"Intersection of user IDs in train and test sets:\", len(set(full_train_df['user_id'].unique()).intersection(set(full_test_df['user_id'].unique()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataEntry:\n",
    "    \"\"\"\n",
    "    Class for saving the data entries (sequences) extracted from the raw data.\n",
    "\n",
    "    Fields:\n",
    "        student_id: ID of the student\n",
    "        question_ids: list of question IDs the student has answered\n",
    "        answers: list of answers the student has given to the questions\n",
    "        skill_ids: list of skill IDs of the questions\n",
    "    \"\"\"\n",
    "\n",
    "    student_id = -1\n",
    "    question_ids = []\n",
    "    answers = []\n",
    "    skill_ids = []\n",
    "\n",
    "    def __init__(self, student_id, question_ids, answers, skill_ids):\n",
    "        self.student_id = student_id\n",
    "        self.question_ids = question_ids\n",
    "        self.answers = answers\n",
    "        self.skill_ids = skill_ids\n",
    "\n",
    "    def __str__(self): # for printing the object\n",
    "        return f'student_id: {self.student_id}, question_ids: {self.question_ids}, answers: {self.answers}, skill_ids: {self.skill_ids}'\n",
    "    \n",
    "    def __eq__(self, other): # necessary to find duplicates in a list of DataEntry objects\n",
    "        if self.student_id != other.student_id:\n",
    "            return False # two similar sequences but with different student IDs are not considered duplicates\n",
    "        for i in range(len(self.question_ids)):\n",
    "            if self.question_ids[i] != other.question_ids[i] or self.answers[i] != other.answers[i] or self.skill_ids[i] != other.skill_ids[i]: # if any field is different, the two sequences are not duplicates\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data_entries(df):\n",
    "    \"\"\"\n",
    "    Function to extract all sequences from the raw data.\n",
    "\n",
    "    Args:\n",
    "        df: the pandas dataframe from the raw data\n",
    "\n",
    "    Returns:\n",
    "        all_data_entries: list of all sequences from the raw data which are extracted from the students in the given dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    to_be_removed_array = []\n",
    "    source_ids = df['user_id'].unique() # Find all unique student IDs in the current dataframe\n",
    "    all_data_entries = []\n",
    "    for student_id in source_ids:\n",
    "        student_df = df[df['user_id'] == student_id].copy() # Find all entries of the current specific student\n",
    "        # Extract the necessary fields from the dataframe\n",
    "        question_ids = student_df['item_id'].tolist()\n",
    "        answers = student_df['correct'].tolist()\n",
    "        skill_ids = student_df['skill_id'].tolist()\n",
    "        # If all of answers are 1 or 0, then skip this data entry, as it is not informative (i.e., the student totally knows the concept, or does not know it at all and does not seem to learn it in the given sequence of questions)\n",
    "        if sum(answers) == 0 or sum(answers) == len(answers):\n",
    "            to_be_removed_array.append(student_id)\n",
    "            continue\n",
    "        data_entry = DataEntry(student_id, question_ids, answers, skill_ids)\n",
    "        # Check if this has not been appended before\n",
    "        if data_entry not in all_data_entries:\n",
    "            all_data_entries.append(data_entry)\n",
    "    print(f\"Number of to be removed students: {len(to_be_removed_array)}\")\n",
    "    print(\"Number of total sequences:\", len(all_data_entries))\n",
    "    return all_data_entries\n",
    "\n",
    "\n",
    "all_train_data_entries = get_all_data_entries(full_train_df)\n",
    "all_test_data_entries = get_all_data_entries(full_test_df)\n",
    "\n",
    "print(\"Number of sequences in the train set:\", len(all_train_data_entries))\n",
    "print(\"Number of sequences in the test set:\", len(all_test_data_entries))\n",
    "\n",
    "with open(f'intermediate_files/train-data-entries-{dataset_name}.json', 'w') as f:\n",
    "    json.dump([entry.__dict__ for entry in all_train_data_entries], f, cls=NpEncoder)\n",
    "with open(f'intermediate_files/test-data-entries-{dataset_name}.json', 'w') as f:\n",
    "    json.dump([entry.__dict__ for entry in all_test_data_entries], f, cls=NpEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read into dataframes\n",
    "train_df = pd.read_json(f'intermediate_files/train-data-entries-{dataset_name}.json')\n",
    "test_df = pd.read_json(f'intermediate_files/test-data-entries-{dataset_name}.json')\n",
    "\n",
    "# Shuffle\n",
    "train_df = train_df.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "test_df = test_df.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "# Check for correct loading\n",
    "print(\"Number of sequences in the train set:\", len(train_df))\n",
    "print(\"Number of sequences in the test set:\", len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [train_df, test_df]\n",
    "all_jsonl_files = []\n",
    "\n",
    "# Generate texts for fine-tuning GPT-3 for each dataframe\n",
    "for df in dfs:\n",
    "    all_jsonl_data = []\n",
    "    for index, row in df.iterrows():\n",
    "        for i in range(1, len(row['question_ids'])):\n",
    "            answers = row['answers'][:i]\n",
    "            answers_without_last = answers[:-1]\n",
    "            count_of_zero = answers_without_last.count(0)\n",
    "            count_of_one = answers_without_last.count(1)\n",
    "            # add a space between each digit of count_of_zero and count_of_one\n",
    "            count_of_zero = ' '.join(str(count_of_zero))\n",
    "            count_of_one = ' '.join(str(count_of_one))\n",
    "            question_ids = row['question_ids'][:i]\n",
    "            current_question_id = question_ids[-1]\n",
    "            current_question_id = ' '.join(str(current_question_id))\n",
    "            prompt = \"\"\n",
    "            if approach == \"extended\":\n",
    "                skill_ids = row['skill_ids'][:i]\n",
    "                current_skill_id = skill_ids[-1]\n",
    "                current_skill_id_str = ' '.join(str(current_skill_id))\n",
    "                prompt += \"Current skill ID: \" + current_skill_id_str + \"\\n\"\n",
    "                count_of_current_skill_id_with_answer_0 = 0\n",
    "                count_of_current_skill_id_with_answer_1 = 0\n",
    "                for k in range(len(question_ids) - 1):\n",
    "                    if skill_ids[k] == current_skill_id:\n",
    "                        if answers[k] == 1:\n",
    "                            count_of_current_skill_id_with_answer_1 += 1\n",
    "                        else:\n",
    "                            count_of_current_skill_id_with_answer_0 += 1\n",
    "                count_of_current_skill_id_with_answer_0 = ' '.join(str(count_of_current_skill_id_with_answer_0))\n",
    "                count_of_current_skill_id_with_answer_1 = ' '.join(str(count_of_current_skill_id_with_answer_1))\n",
    "                prompt += \"Total correct for prior questions with skill ID \" + str(current_skill_id_str) + \" : \" + str(count_of_current_skill_id_with_answer_1) + \"\\n\"\n",
    "                prompt += \"Total wrong for prior questions with skill ID \" + str(current_skill_id_str) + \" : \" + str(count_of_current_skill_id_with_answer_0) + \"\\n\"\n",
    "            prompt += f\"Total correct until now: {count_of_one}\\nTotal wrong until now: {count_of_zero}\\nCurrent question ID: {current_question_id}\\nStudent response: \"\n",
    "            current_student_response = answers[-1]\n",
    "            completion = ('CORRECT' if int(current_student_response) == 1 else 'WRONG')\n",
    "            all_jsonl_data.append(JSONLDataObject(prompt, completion))\n",
    "    all_jsonl_files.append(all_jsonl_data)\n",
    "\n",
    "for i in range(len(all_jsonl_files)):\n",
    "    random.shuffle(all_jsonl_files[i])\n",
    "\n",
    "dump_jsonl(all_jsonl_files[0], f'jsonl_files/{dataset_name}-{approach}-train.jsonl')\n",
    "dump_jsonl(all_jsonl_files[1], f'jsonl_files/{dataset_name}-{approach}-test.jsonl')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
